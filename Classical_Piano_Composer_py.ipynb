{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classical-Piano-Composer.py",
      "provenance": [],
      "authorship_tag": "ABX9TyOpLKwkFBgzLVwBv0q2dgK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimab16/Music-Generation-LSTM-GAN/blob/main/Classical_Piano_Composer_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the dataset from github"
      ],
      "metadata": {
        "id": "hKP5DbHTVxHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nimab16/Music-Generation-LSTM-GAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iQ4m52YLQ9k",
        "outputId": "ad182cca-e432-47a5-85fb-b8a62c69dc87"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Music-Generation-LSTM-GAN' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install libraries"
      ],
      "metadata": {
        "id": "l3M0BZqIV4Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install music21\n",
        "!pip install Keras\n",
        "!pip install Tensorflow\n",
        "!pip install h5py"
      ],
      "metadata": {
        "id": "ygmDjoaOd4_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdcd398e-230e-4c90-cb81-0e2e255e9fdc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: music21 in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: Tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0+zzzcolab20220506162203)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.46.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.14.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (0.25.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (0.5.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 35.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->Tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->Tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->Tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->Tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->Tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->Tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the librarries for train and prepare sequences \n",
        "This module prepares midi file data and feeds it to the neural network for training"
      ],
      "metadata": {
        "id": "qqOTL4zSJD70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os \n",
        "os.chdir('/content/Music-Generation-LSTM-GAN')\n",
        "import os\n",
        "import sys\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)\n"
      ],
      "metadata": {
        "id": "VPx6wiDEeIc2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pickle\n",
        "import numpy\n",
        "from music21 import converter, instrument, note, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "swB0P_PMJYJT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get all the notes and chords\n",
        "Get all the notes and chords from the midi files in the ./midi_songs directory"
      ],
      "metadata": {
        "id": "VMV8z1WTJm55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes():\n",
        "    \"\"\"  \"\"\"\n",
        "    notes = []\n",
        "\n",
        "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi)\n",
        "            notes_to_parse = s2.parts[0].recurse() \n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    with open('data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes"
      ],
      "metadata": {
        "id": "S6AEfvEoJxpC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the sequences\n",
        "Prepare the sequences used by the Neural Network"
      ],
      "metadata": {
        "id": "tJ53AB0tJ4F7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "   \n",
        "    sequence_length = 100\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "     # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "metadata": {
        "id": "YrRohf3sKA68"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the structure of model\n",
        "create the structure of the neural network"
      ],
      "metadata": {
        "id": "gxRdwHWwKR2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "c0-og4VlKl1c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model with check point"
      ],
      "metadata": {
        "id": "8mQhdql2Kn59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VGRyBmXUIsok"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train(model, network_input, network_output):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    model.fit(network_input, network_output, epochs=20, batch_size=128, callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call all functions by order\n",
        "Train a Neural Network to generate music"
      ],
      "metadata": {
        "id": "J8xnCflPJa3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network():\n",
        "    \n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "metadata": {
        "id": "oNYJ68S-JlzH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# call train method to run the program"
      ],
      "metadata": {
        "id": "Y7gNp_2NVqXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_network()"
      ],
      "metadata": {
        "id": "WmXn0VVSL5ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate classic music based on the pretrained model \n",
        "I generate the piano music based on **weights.hdf5** "
      ],
      "metadata": {
        "id": "wkkS9vVHYJoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python Predict_Classical_Piano_Composer.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Gvf6xqYfFy",
        "outputId": "e0a123ae-0aaa-4263-8b01-3f846764d7eb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"Predict_Classical_Piano_Composer.ipynb\", line 9, in <module>\n",
            "    \"include_colab_link\": true\n",
            "NameError: name 'true' is not defined\n"
          ]
        }
      ]
    }
  ]
}