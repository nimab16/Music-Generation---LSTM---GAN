{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classical-Piano-Composer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2b9zaKL5L7mX0An/4A7i0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimab16/Music-Generation-LSTM-GAN/blob/main/Classical_Piano_Composer_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the dataset from github"
      ],
      "metadata": {
        "id": "hKP5DbHTVxHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nimab16/Music-Generation-LSTM-GAN"
      ],
      "metadata": {
        "id": "2iQ4m52YLQ9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install libraries"
      ],
      "metadata": {
        "id": "l3M0BZqIV4Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install music21\n",
        "!pip install Keras\n",
        "!pip install Tensorflow\n",
        "!pip install h5py"
      ],
      "metadata": {
        "id": "ygmDjoaOd4_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the librarries for train and prepare sequences \n",
        "This module prepares midi file data and feeds it to the neural network for training"
      ],
      "metadata": {
        "id": "qqOTL4zSJD70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os \n",
        "os.chdir('/content/Music-Generation-LSTM-GAN')\n",
        "import os\n",
        "import sys\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)\n"
      ],
      "metadata": {
        "id": "VPx6wiDEeIc2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pickle\n",
        "import numpy\n",
        "from music21 import converter, instrument, note, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "swB0P_PMJYJT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get all the notes and chords\n",
        "Get all the notes and chords from the midi files in the ./midi_songs directory"
      ],
      "metadata": {
        "id": "VMV8z1WTJm55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes():\n",
        "    \"\"\"  \"\"\"\n",
        "    notes = []\n",
        "\n",
        "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi)\n",
        "            notes_to_parse = s2.parts[0].recurse() \n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    with open('data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes"
      ],
      "metadata": {
        "id": "S6AEfvEoJxpC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the sequences\n",
        "Prepare the sequences used by the Neural Network"
      ],
      "metadata": {
        "id": "tJ53AB0tJ4F7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "   \n",
        "    sequence_length = 100\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "     # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "metadata": {
        "id": "YrRohf3sKA68"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the structure of model\n",
        "create the structure of the neural network"
      ],
      "metadata": {
        "id": "gxRdwHWwKR2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "c0-og4VlKl1c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model with check point"
      ],
      "metadata": {
        "id": "8mQhdql2Kn59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VGRyBmXUIsok"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train(model, network_input, network_output):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    model.fit(network_input, network_output, epochs=20, batch_size=128, callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call all functions by order\n",
        "Train a Neural Network to generate music"
      ],
      "metadata": {
        "id": "J8xnCflPJa3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network():\n",
        "    \n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "metadata": {
        "id": "oNYJ68S-JlzH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# call train method to run the program"
      ],
      "metadata": {
        "id": "Y7gNp_2NVqXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_network()"
      ],
      "metadata": {
        "id": "WmXn0VVSL5ZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}